{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fa06da-5a50-4f85-bed2-985c388a2aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 14s 213ms/step - loss: 0.6058 - accuracy: 0.6480 - val_loss: 0.4259 - val_accuracy: 0.8010\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 13s 206ms/step - loss: 0.2603 - accuracy: 0.9035 - val_loss: 0.1209 - val_accuracy: 0.9570\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 13s 207ms/step - loss: 0.1450 - accuracy: 0.9465 - val_loss: 0.1439 - val_accuracy: 0.9480\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 13s 207ms/step - loss: 0.1015 - accuracy: 0.9595 - val_loss: 0.1029 - val_accuracy: 0.9560\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 13s 208ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0961 - val_accuracy: 0.9610\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 16s 148ms/step - loss: 0.2457 - accuracy: 0.9145 - val_loss: 0.7354 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.7235 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 0.7520 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.0142 - accuracy: 0.9985 - val_loss: 0.7445 - val_accuracy: 0.4880\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.7656 - val_accuracy: 0.4350\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 29s 266ms/step - loss: 0.2555 - accuracy: 0.8905 - val_loss: 0.7559 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.0506 - accuracy: 0.9890 - val_loss: 0.8165 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.0157 - accuracy: 0.9990 - val_loss: 0.8717 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 15s 238ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 15s 238ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14fedfda4610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, ResNet152\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Download and extract the dataset\n",
    "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "zip_file = tf.keras.utils.get_file(\"cats_and_dogs_filtered.zip\", url, extract=True)\n",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'cats_and_dogs_filtered')\n",
    "\n",
    "# Set up directories for training and validation data\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Load pre-trained models\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False)\n",
    "resnet50_base = ResNet50(weights='imagenet', include_top=False)\n",
    "resnet152_base = ResNet152(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom classifier layers on top of the pre-trained models\n",
    "def add_custom_layers(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Output layer with binary classification\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Create models with custom layers\n",
    "vgg16_model = add_custom_layers(vgg16_base)\n",
    "resnet50_model = add_custom_layers(resnet50_base)\n",
    "resnet152_model = add_custom_layers(resnet152_base)\n",
    "\n",
    "# Compile models\n",
    "# sgd = SGD(lr=0.001, momentum=0.9)\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# sgd = legacy.SGD(lr=0.001, momentum=0.9)\n",
    "sgd = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "vgg16_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet50_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet152_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "trainable_variables = []\n",
    "for model in [vgg16_model, resnet50_model, resnet152_model]:\n",
    "    trainable_variables.extend(model.trainable_variables)\n",
    "\n",
    "sgd.build(trainable_variables)\n",
    "\n",
    "\n",
    "# Train the models\n",
    "num_epochs = 5\n",
    "\n",
    "vgg16_model.fit(train_generator, epochs=num_epochs, validation_data=valid_generator)\n",
    "resnet50_model.fit(train_generator, epochs=num_epochs, validation_data=valid_generator)\n",
    "resnet152_model.fit(train_generator, epochs=num_epochs, validation_data=valid_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad1988-0907-4cd8-bf2c-4dce59f6c669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae49b2f-065c-4362-a429-21e7716b4d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
